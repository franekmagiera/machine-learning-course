{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will implement one-vs-all logistic regression and a neural network to predict hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X.csv file contains a 5000x400 matrix where every row is a training example representing a 20x20 pixel image (all pixels' grayscale values are in a row one after another). There are 5000 training examples which are a subset of the MNIST handwritten digit dataset. y.csv contains a 5000 dimensional vector containing labels for the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('X.csv', delimiter=',')\n",
    "y = np.genfromtxt('y.csv', delimiter=',')\n",
    "y[y == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 9.],\n",
       "       [6., 2., 2.],\n",
       "       [7., 8., 2.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import sample\n",
    "indexes = sample(range(len(X)), 9)\n",
    "for i in range(9):\n",
    "    image = X[indexes[i],:].reshape((20,20), order='F').copy()\n",
    "    plt.subplot(331+i)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "y[indexes].reshape((3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regularised logistic regression the cost function is defined as $J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} [-y^{(i)} log(h_\\theta(x^{(i)})) - (1-y^{(i)}) log(1-h_\\theta(x^{(i)}))] + \\frac{\\lambda}{2m} \\sum_{j=1}^{n} \\theta_j^2$ where $h_\\theta(x^{(i)}) = g(\\theta^T x^{(i)})$ and g is the sigmoid function. Hence the partial derivatives of above cost functions are defined as: $\\frac{\\partial J}{\\partial \\theta_0} = \\frac{1}{m} \\sum_{i=1}^{m}(h_\\theta(x^{(i)})- y^{(i)})x_j^{(i)}$ for $j = 0$ and $\\frac{\\partial J}{\\partial \\theta_j} =(\\frac{1}{m} \\sum_{i=1}^{m}(h_\\theta(x^{(i)})- y^{(i)})x_j^{(i)}) + \\frac{\\lambda}{m}\\theta_j$ for $j \\geq 1$. Having vectorized we get the following formula for the gradient: $\\frac{\\partial J}{\\partial \\theta} = \\frac{1}{m} X^T (h_\\theta(x) - y) + \\frac{\\lambda}{m} \\theta^\\prime$ where $\\theta^\\prime$ is equal to $\\theta$ for $j \\geq 1$ and $0$ for $j = 0$ (not regularising bias)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "def sigmoid(x):\n",
    "    if isinstance(x, Number):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    else:\n",
    "        return np.divide(np.ones(x.shape), np.add(np.ones(x.shape), np.exp(np.negative(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(theta, X, y, regularisation_parameter):\n",
    "    m = X.shape[0]\n",
    "    h = sigmoid(X@theta)\n",
    "    return 1/m * sum(np.subtract(np.multiply(np.negative(y), np.log(h)), np.multiply(np.subtract(np.ones(m), y), np.log(np.subtract(np.ones(m), h))))) + regularisation_parameter/2/m * sum(np.power(theta[1:], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, regularisation_parameter):\n",
    "    m = X.shape[0]\n",
    "    theta2 = theta.copy()\n",
    "    theta2[0] = 0\n",
    "    return (1/m * np.dot(np.transpose(X), sigmoid(X@theta) - y) + regularisation_parameter/m * theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.534819396109744\n",
      "[ 0.14656137 -0.54855841  0.72472227  1.39800296]\n"
     ]
    }
   ],
   "source": [
    "# testing whether cost_function and gradient are working as expected\n",
    "theta_t = np.array([-2, -1, 1, 2])\n",
    "X_t = np.concatenate((np. ones((5,1)), np.arange(1,16).reshape((5,3), order='F')/10), axis=1)\n",
    "y_t = np.array([1, 0, 1, 0, 1])\n",
    "lambda_t = 3\n",
    "print(cost_function(theta_t, X_t, y_t, lambda_t))\n",
    "print(gradient(theta_t, X_t, y_t, lambda_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to train 10 classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_labels, regularisation_parameter):\n",
    "    m = X.shape[0] # number of training instances \n",
    "    n = X.shape[1] # number of parameters - pixels in this case\n",
    "    \n",
    "    theta = np.zeros((num_labels, n+1)) # preallocation of matrix of classifier parameters\n",
    "    X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
    "    initial_theta = np.zeros(n+1)\n",
    "    for c in range(num_labels):\n",
    "        y2 = y.copy()\n",
    "        y2 = np.array([1 if i == c else 0 for i in y2])\n",
    "        theta[c] = optimize.fmin_cg(lambda x: cost_function(x, X, y2, regularisation_parameter), initial_theta, fprime=lambda x: gradient(x, X, y2, regularisation_parameter))\n",
    "        #theta[c] = optimize.minimize(cost_function, initial_theta, args=(X, y2, regularisation_parameter), method='CG', jac=gradient)\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.008572\n",
      "         Iterations: 102\n",
      "         Function evaluations: 394\n",
      "         Gradient evaluations: 394\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013126\n",
      "         Iterations: 112\n",
      "         Function evaluations: 425\n",
      "         Gradient evaluations: 425\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.050818\n",
      "         Iterations: 189\n",
      "         Function evaluations: 568\n",
      "         Gradient evaluations: 568\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.057603\n",
      "         Iterations: 293\n",
      "         Function evaluations: 886\n",
      "         Gradient evaluations: 886\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.033095\n",
      "         Iterations: 152\n",
      "         Function evaluations: 490\n",
      "         Gradient evaluations: 490\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.054467\n",
      "         Iterations: 240\n",
      "         Function evaluations: 709\n",
      "         Gradient evaluations: 709\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.018257\n",
      "         Iterations: 163\n",
      "         Function evaluations: 595\n",
      "         Gradient evaluations: 595\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.030648\n",
      "         Iterations: 174\n",
      "         Function evaluations: 597\n",
      "         Gradient evaluations: 597\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078451\n",
      "         Iterations: 302\n",
      "         Function evaluations: 840\n",
      "         Gradient evaluations: 840\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.071210\n",
      "         Iterations: 268\n",
      "         Function evaluations: 736\n",
      "         Gradient evaluations: 736\n"
     ]
    }
   ],
   "source": [
    "theta = oneVsAll(X, y, 10, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(index):\n",
    "    image = X[index,:].reshape((20,20), order='F').copy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.9149877 , -20.28463228,  -4.99614587,  -9.82525013,\n",
       "       -13.60077991,  -3.54267133,  -3.73200207, -15.97269068,\n",
       "       -12.77239308, -16.60058331])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "index = randint(0, X.shape[0])\n",
    "print(index)\n",
    "theta.dot(np.insert(X[index], 0, 1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_number(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_vs_all(theta, X):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
    "    predictions = X.dot(np.transpose(theta))\n",
    "    return np.argmax(predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9646"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict_one_vs_all(theta, X) == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My classifier classified 96% of training set instances correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression cannot form more complex hypotheses because it is a linear classifier. I could add more features (like in a previous exercise) but it could be very expensive to train. The goal of the next exercise is to build a feedforward propagation algorithm for a neural network. I will use parameters that has already been trained and supplied by the lecturer. Neural networks are able to represent complex, non-linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given neural network has 3 layers - input layer of size 400 (plus one bias unit that is always equal to 1), hidden layer of 25 units (plus one bias unit) and output layer with 10 units (because there are only 10 digits to classify). Hence Theta1 has a shape of (25, 401) and Theta2 has a shape of (10, 26)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401) (10, 26) (5000, 400)\n"
     ]
    }
   ],
   "source": [
    "Theta1 = np.genfromtxt('Theta1.csv', delimiter=',')\n",
    "Theta2 = np.genfromtxt('Theta2.csv', delimiter=',')\n",
    "print(Theta1.shape, Theta2.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(Theta1, Theta2, X):\n",
    "    m = X.shape[0]\n",
    "    X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
    "    \n",
    "    a2 = sigmoid(X.dot(np.transpose(Theta1)))\n",
    "    a2 = np.insert(a2, 0, 1, axis=1)\n",
    "    \n",
    "    return np.argmax(sigmoid(a2.dot(np.transpose(Theta2))), axis=1) + 1 # Adding one because of different indexing in MATLAB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9752"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.genfromtxt('y.csv', delimiter=',') # importing original y once again because of different MATLAB indexing\n",
    "(predict_nn(Theta1, Theta2, X) == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network accuracy is about 97.5%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
