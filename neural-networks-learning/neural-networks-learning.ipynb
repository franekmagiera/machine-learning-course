{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to implement the backpropagation algorithm for neural networks and use it for hand-written digit recognition.\n",
    "\n",
    "In the X.csv file there are 5000 training examples that are 20x20 grayscale images of the hand-written digits (from the MNIST database). Each 20x20 image has been unrolled into a 400 dimensional vector and became a row in the 5000x400 matrix X. In the y.csv file there is a 5000 dimensional vector of labels for the training set.\n",
    "\n",
    "I start by reading the data and visualising it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = np.genfromtxt('X.csv', delimiter=',')\n",
    "y = np.genfromtxt('y.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import sample\n",
    "rows = 3\n",
    "cols = 3\n",
    "fig, ax = plt.subplots(rows, cols)\n",
    "indexes = sample(range(1, X.shape[0]+1), rows*cols)\n",
    "indexes = np.reshape(indexes, (rows, cols))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        ax[i, j].imshow(X[indexes[i, j]].reshape(20, 20, order='F'))\n",
    "        ax[i, j].axis('off')\n",
    "        ax[i, j].set_title(int(y[indexes[i, j]]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network used in the exercise will be a very simple one comprising 3 layers - an input layer, a hidden layer and an output layer. Inputs are pixel values of a 20x20 pixel image, so there will be 400 input units and 1 bias unit. I already have a set of network parameters $(\\Theta^{(1)}, \\Theta^{(2)})$ provided by a course lecturer. The second layer has 25 units and the output layer has 10 output units (because there are 10 digits 0-9). Hence $\\Theta^{(1)}$ is 25x401 dimensional and $\\Theta^{(2)}$ is 10x26 dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 401), (10, 26)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta1 = np.genfromtxt('Theta1.csv', delimiter=',')\n",
    "Theta2 = np.genfromtxt('Theta2.csv', delimiter=',')\n",
    "[Theta1.shape, Theta2.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will implement feedforward propagation and the cost function. The cost function for the neural network (without regularisation) is: $J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\sum_{j=1}^K [-y_k^{(i)} log((h_\\theta(x^{(i)}))_k) - (1 - y_k^{(i)}) log(1 - (h_\\theta(x^{(i)}))_k)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending column of ones at the beginning of X matrix to take bias units into account.\n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will have to recode $y$ so the labels are vectors containing only 0 or 1. For example when $y^{(i)} = 5$ then $y^{(i)} = [0, 0, 0, 0, 1, 0, 0, 0, 0]$. I will recode $y$ to be a matrix $Y$ containg each label in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.zeros((len(y), 10))\n",
    "for index, row in enumerate(Y):\n",
    "    row[int(y[index])] = 1\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numbers import Number\n",
    "def sigmoid(x):\n",
    "    if isinstance(x, Number):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    else:\n",
    "        return np.divide(np.ones(x.shape), np.add(np.ones(x.shape), np.exp(np.negative(x))))\n",
    "\n",
    "def sigmoid_gradient(x):\n",
    "    if isinstance(x, Number):\n",
    "        return sigmoid(x)*(1 - sigmoid(x))\n",
    "    else:\n",
    "        return np.multiply(sigmoid(x), (np.subtract(np.ones(x.shape), sigmoid(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.28762916516131876, 0.3844877962428938]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nn_cost_function_matlab_indexing(theta, input_layer_size, hidden_layer_size, num_labels, X, Y, regularisation_parameter):\n",
    "    '''\n",
    "    This function takes into account the fact that neural network\\'s Theta1 and Theta2 parameters\n",
    "    supplied by a course lecturer have been derived in MATLAB where array indexing is different than\n",
    "    in Python and my model. So in order for it to calculate correct values I have to change the order\n",
    "    of columns in Htheta - the last column should become the first.\n",
    "    '''\n",
    "    Theta1 = np.reshape(theta[:hidden_layer_size*(input_layer_size+1)], (hidden_layer_size, input_layer_size+1), order='F')\n",
    "    Theta2 = np.reshape(theta[hidden_layer_size*(input_layer_size+1):], (num_labels, hidden_layer_size+1), order='F')\n",
    "    m = X.shape[0]\n",
    "    K = Y.shape[1]\n",
    "    # Feedforward.\n",
    "    z2 = (Theta1 @ np.transpose(X)) # Now every column contains a transformed training example.\n",
    "    a2 = sigmoid(z2)\n",
    "    # Appending a row of ones to take bias into account.\n",
    "    a2 = np.insert(a2, 0, 1, axis=0)\n",
    "    z3 = np.transpose(Theta2 @ a2) # Now every row contains an output value.\n",
    "    Htheta = sigmoid(z3) # Every row contains a hypothesis value.\n",
    "    # Have to change the last row with the first one because of different indexing in MATLAB.\n",
    "    Htheta = np.insert(Htheta, 0, Htheta[:, -1], axis=1) # 1\n",
    "    Htheta = np.delete(Htheta, 10, axis=1) # 2\n",
    "    #\n",
    "    # Cost function.\n",
    "    J = 1/m * sum(sum(np.subtract(np.multiply(-Y, np.log(Htheta)), np.multiply(np.subtract(np.ones(Y.shape), Y), np.log(np.subtract(np.ones(Y.shape), Htheta))))))\n",
    "    J += regularisation_parameter/(2*m) * (sum(sum(np.square(Theta1))) + sum(sum(np.square(Theta2))))\n",
    "    return J\n",
    "#[nn_cost_function_matlab_indexing(Theta1, Theta2, X, Y, 0), nn_cost_function_matlab_indexing(Theta1, Theta2, X, Y, 1)]\n",
    "theta = np.concatenate((Theta1.T.ravel(), Theta2.T.ravel()))\n",
    "[nn_cost_function_matlab_indexing(theta, 400, 25, 10, X, Y, 0),\\\n",
    " nn_cost_function_matlab_indexing(theta, 400, 25, 10, X, Y, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computed values are correct (they were compared with values provided in the exercise description). I had to take into account MATLAB's array indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_cost_function1(theta, input_layer_size, hidden_layer_size, num_labels, X, Y, regularisation_parameter):\n",
    "    '''\n",
    "    This function should work for Python indexing.\n",
    "    '''\n",
    "    Theta1 = np.reshape(theta[:hidden_layer_size*(input_layer_size+1)], (hidden_layer_size, input_layer_size+1), order='F')\n",
    "    Theta2 = np.reshape(theta[hidden_layer_size*(input_layer_size+1):], (num_labels, hidden_layer_size+1), order='F')\n",
    "    m = X.shape[0]\n",
    "    K = Y.shape[1]\n",
    "    # Feedforward.\n",
    "    z2 = (Theta1 @ np.transpose(X)) # Now every column contains a transformed training example.\n",
    "    a2 = sigmoid(z2)\n",
    "    # Appending a row of ones to take bias into account.\n",
    "    a2 = np.insert(a2, 0, 1, axis=0)\n",
    "    z3 = np.transpose(Theta2 @ a2) # Now every row contains an output value.\n",
    "    Htheta = sigmoid(z3) # Every row contains a hypothesis value.\n",
    "    # Cost function.\n",
    "    J = 1/m * sum(sum(np.subtract(np.multiply(-Y, np.log(Htheta)), np.multiply(np.subtract(np.ones(Y.shape), Y), np.log(np.subtract(np.ones(Y.shape), Htheta))))))\n",
    "    J += regularisation_parameter/(2*m) * (sum(sum(np.square(Theta1))) + sum(sum(np.square(Theta2))))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training neural networks it is important to randomly initialize the weights for the purpouses of symmetry breaking. Proposed strategy is to select random values for $\\Theta^{(l)}$ uniformly from the range $[-\\epsilon_{init}, \\epsilon_{init}]$. It is advised to choose $\\epsilon_{init}$ based on the number of units in layers adjacent to the weights according to the formula: $\\frac{\\sqrt{6}}{\\sqrt{L_{in} + L_{out}}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11867816581938531"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lin = 401\n",
    "Lout = 25\n",
    "eps_init = np.sqrt(6)/np.sqrt(Lin + Lout)\n",
    "eps_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case $\\epsilon_{init} \\approx 0.12$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyTheta1 = np.random.uniform(-eps_init, eps_init, (25, 401))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for $\\Theta^{(2)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40824829046386296"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lin = 26\n",
    "Lout = 10\n",
    "eps_init = np.sqrt(6)/np.sqrt(Lin + Lout)\n",
    "eps_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyTheta2 = np.random.uniform(-eps_init, eps_init, (10, 26))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can implement backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.100653841000583,\n",
       " array([-0.01670225, -0.05706508,  0.13391778, ...,  0.18205814,\n",
       "         0.12377217,  0.19236865])]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nn_cost_function2(theta, input_layer_size, hidden_layer_size, num_labels, X, Y, regularisation_parameter):\n",
    "    '''\n",
    "    This function should work for Python indexing.\n",
    "    '''\n",
    "    Theta1 = np.reshape(theta[:hidden_layer_size*(input_layer_size+1)], (hidden_layer_size, input_layer_size+1), order='F')\n",
    "    Theta2 = np.reshape(theta[hidden_layer_size*(input_layer_size+1):], (num_labels, hidden_layer_size+1), order='F')\n",
    "    m = X.shape[0]\n",
    "    K = Y.shape[1]\n",
    "    # Feedforward.\n",
    "    z2 = (Theta1 @ np.transpose(X)) # Now every column contains a transformed training example.\n",
    "    a2 = sigmoid(z2)\n",
    "    # Appending a row of ones to take bias into account.\n",
    "    a2 = np.insert(a2, 0, 1, axis=0)\n",
    "    z3 = np.transpose(Theta2 @ a2) # Now every row contains an output value.\n",
    "    Htheta = sigmoid(z3) # Every row contains a hypothesis value.\n",
    "    # Cost function.\n",
    "    J = 1/m * sum(sum(np.subtract(np.multiply(-Y, np.log(Htheta)), np.multiply(np.subtract(np.ones(Y.shape), Y), np.log(np.subtract(np.ones(Y.shape), Htheta))))))\n",
    "    J += regularisation_parameter/(2*m) * (sum(sum(np.square(Theta1))) + sum(sum(np.square(Theta2))))\n",
    "    # Backpropagation.\n",
    "    a3 = np.copy(Htheta)\n",
    "    delta3 = np.subtract(a3, Y)\n",
    "    delta2 = np.multiply(np.transpose(Theta2) @ np.transpose(delta3), sigmoid_gradient(np.insert(z2, 0, 1, axis=0)))\n",
    "    # Removing \"error term\" coming from bias term.\n",
    "    delta2 = np.delete(delta2, 0, axis=0) # Now every column contains \"error term\" for layer 2. \n",
    "    DELTA2 = np.transpose(delta3)@np.transpose(a2)\n",
    "    DELTA1 = delta2@X\n",
    "    D1 = DELTA1/m\n",
    "    D2 = DELTA2/m\n",
    "    # Regularisation\n",
    "    Theta12 = np.copy(Theta1)\n",
    "    Theta12[:, 0] = 0\n",
    "    D1 = np.add(D1, regularisation_parameter/m * Theta12)\n",
    "    Theta22 = np.copy(Theta2)\n",
    "    Theta22[:, 0] = 0\n",
    "    D2 = np.add(D2, regularisation_parameter/m * Theta22)\n",
    "    # Unrolling gradients.\n",
    "    grad = np.concatenate((D1.T.ravel(), D2.T.ravel()))\n",
    "    return [J, grad]\n",
    "mytheta = np.concatenate((MyTheta1.T.ravel(), MyTheta2.T.ravel()))\n",
    "Jval, grad = nn_cost_function2(mytheta, 400, 25, 10, X, Y, 0)\n",
    "[Jval, grad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to check if my backpropagation implementation is correct I will perform gradient checking using gradient values computed numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function = lambda p: nn_cost_function1(p, 400, 25, 10, X, Y, 0)\n",
    "def compute_numerical_gradient(cost_function, theta):\n",
    "    numgrad = np.zeros(theta.size)\n",
    "    perturb = np.zeros(theta.size)\n",
    "    e = 1e-4\n",
    "    for index, p in enumerate(range(theta.size)):\n",
    "        perturb[index] = e;\n",
    "        loss1 = cost_function(np.subtract(theta, perturb))\n",
    "        loss2 = cost_function(np.add(theta, perturb))\n",
    "        numgrad[index] = (loss2 - loss1) / (2*e)\n",
    "        perturb[index] = 0\n",
    "    return numgrad\n",
    "numerical_gradient = compute_numerical_gradient(cost_function, mytheta) #unregularised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.264565138064996e-10"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.linalg.norm(np.subtract(numerical_gradient, grad))/np.linalg.norm(np.add(numerical_gradient, grad))\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative difference between numerically computed gradient and derived analytically from backpropagation is smaller than 1e-9 so I have strong evidence that my implementation of backpropagation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.10672129216892,\n",
       " array([-0.01670225, -0.05706508,  0.13391778, ...,  0.18198475,\n",
       "         0.12378148,  0.19243862])]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_Jval, reg_grad = nn_cost_function2(mytheta, 400, 25, 10, X, Y, 1)\n",
    "[reg_Jval, reg_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3903877655565138e-05"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_function = lambda p: nn_cost_function1(p, 400, 25, 10, X, Y, 1)\n",
    "reg_numerical_gradient = compute_numerical_gradient(cost_function, mytheta)\n",
    "diff = np.linalg.norm(np.subtract(reg_numerical_gradient, reg_grad))/np.linalg.norm(np.add(reg_numerical_gradient, reg_grad))\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the difference is very small so I am more confident in my implementation. Now I can train the neural network using SciPy's fmin_cg function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.349878\n",
      "         Iterations: 163\n",
      "         Function evaluations: 491\n",
      "         Gradient evaluations: 480\n"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "regularisation_parameter = 1\n",
    "optimal_theta = optimize.fmin_cg(f=lambda x: nn_cost_function2(x, 400, 25, 10, X, Y, regularisation_parameter)[0],\n",
    "                                 x0=mytheta,\n",
    "                                 fprime=lambda x: nn_cost_function2(x, 400, 25, 10, X, Y, regularisation_parameter)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3498779840305942,\n",
       " array([-1.40270125e-03, -5.24233348e-04, -3.75529443e-04, ...,\n",
       "        -2.89622546e-04,  6.04955138e-05, -4.42986531e-04])]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_cost_function2(optimal_theta, 400, 25, 10, X, Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9], dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(theta, input_layer_size, hidden_layer_size, num_labels, X):\n",
    "    Theta1 = np.reshape(theta[:hidden_layer_size*(input_layer_size+1)], (hidden_layer_size, input_layer_size+1), order='F')\n",
    "    Theta2 = np.reshape(theta[hidden_layer_size*(input_layer_size+1):], (num_labels, hidden_layer_size+1), order='F')\n",
    "    m = X.shape[0]\n",
    "    K = Y.shape[1]\n",
    "    # Feedforward.\n",
    "    z2 = (Theta1 @ np.transpose(X)) # Now every column contains a transformed training example.\n",
    "    a2 = sigmoid(z2)\n",
    "    # Appending a row of ones to take bias into account.\n",
    "    a2 = np.insert(a2, 0, 1, axis=0)\n",
    "    z3 = np.transpose(Theta2 @ a2) # Now every row contains an output value.\n",
    "    Htheta = sigmoid(z3) # Every row contains a hypothesis value.\n",
    "    return Htheta\n",
    "\n",
    "predictions = np.argmax(predict(optimal_theta, 400, 25, 10, X), axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.11999999999999"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions == y)/len(y)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My neural network predicts 99.12% of exampels in training sets correctly. Now I am curious which examples were classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2166 4672 4636]\n",
      " [3795 3382 4860]\n",
      " [2593 3627 2187]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "incorrectly_classified = [i for i in range(len(y)) if predictions[i] != y[i]]\n",
    "X2 = np.genfromtxt('X.csv', delimiter=',')\n",
    "rows = 3\n",
    "cols = 3\n",
    "fig, ax = plt.subplots(rows, cols)\n",
    "indexes = sample(incorrectly_classified, rows*cols)\n",
    "indexes = np.reshape(indexes, (rows, cols))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        ax[i, j].imshow(X2[indexes[i, j]].reshape(20, 20, order='F'))\n",
    "        ax[i, j].axis('off')\n",
    "        ax[i, j].set_title(int(y[indexes[i, j]]))\n",
    "plt.tight_layout()\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is noticeable that some of those incorrectly classified examples are really badly written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
